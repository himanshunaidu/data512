{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Politician Articles: Bias\n",
    "\n",
    "This notebook explores bias in data using Wikipedia articles about political figures from different countries. The analysis aims to examine the coverage of politicians on Wikipedia and the quality of articles about politicians across nations. \n",
    "\n",
    "The notebook utilizes data from two sources: \n",
    "- Dataset of Wikipedia articles about politicians using Wikipedia [Category:Politicians_by_nationality](https://en.wikipedia.org/wiki/Category:Politicians_by_nationality).\n",
    "- Dataset of country populations obtained from [World Population Data Sheet](https://www.prb.org/international/indicator/population/table/).\n",
    "\n",
    "Additionally, the machine learning service ORES is used to estimate the quality of each article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article Page Info MediaWiki API\n",
    "\n",
    "The following sub-section contains code to access page info data using the [MediaWiki REST API for the EN Wikipedia](https://www.mediawiki.org/wiki/API:Main_page). This sub-section shows how to request summary 'page info' for a single article page. The API documentation, [API:Info](https://www.mediawiki.org/wiki/API:Info), covers additional details that may be helpful when trying to use or understand this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "This code example was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Modifications to this code were made by Himanshu Naidu on October 13, 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# These are standard python modules\n",
    "import json, time, urllib.parse\n",
    "#\n",
    "# The 'requests' module is not a standard Python module. You will need to install this with pip/pip3 if you do not already have it\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example relies on some constants that help make the code a bit more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The basic English Wikipedia API endpoint\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "API_HEADER_AGENT = 'User-Agent'\n",
    "\n",
    "# We'll assume that there needs to be some throttling for these requests - we should always be nice to a free data resource\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "USER_EMAIL = \"hnaidu36@uw.edu\"\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': f'<{USER_EMAIL}>, University of Washington, MSDS DATA 512 - AUTUMN 2024'\n",
    "}\n",
    "\n",
    "# This is just a list of English Wikipedia article titles that we can use for example requests\n",
    "ARTICLE_TITLES = [ 'Bison', 'Northern flicker', 'Red squirrel', 'Chinook salmon', 'Horseshoe bat' ]\n",
    "\n",
    "# This is a string of additional page properties that can be returned see the Info documentation for\n",
    "# what can be included. If you don't want any this can simply be the empty string\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"talkid|url|watched|watchers\"\n",
    "#PAGEINFO_EXTENDED_PROPERTIES = \"\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",           # to simplify this should be a single page title at a time\n",
    "    \"prop\": \"info\",\n",
    "    \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API request will be made using one procedure. The idea is to make this reusable. The procedure is parameterized, but relies on the constants above for the important parameters. The underlying assumption is that this will be used to request data for a set of article pages. Therefore the parameter most likely to change is the article_title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_pageinfo_per_article(article_title = None, \n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT, \n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "    \n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['titles'] = article_title\n",
    "\n",
    "    if not request_template['titles']:\n",
    "        raise Exception(\"Must supply an article title to make a pageinfo request.\")\n",
    "\n",
    "    if API_HEADER_AGENT not in headers:\n",
    "        raise Exception(f\"The header data should include a '{API_HEADER_AGENT}' field that contains your UW email address.\")\n",
    "\n",
    "    if 'uwnetid@uw' in headers[API_HEADER_AGENT]:\n",
    "        raise Exception(f\"Use your UW email address in the '{API_HEADER_AGENT}' field.\")\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page info data for: Chinook salmon\n",
      "{\n",
      "    \"batchcomplete\": \"\",\n",
      "    \"query\": {\n",
      "        \"pages\": {\n",
      "            \"1212891\": {\n",
      "                \"pageid\": 1212891,\n",
      "                \"ns\": 0,\n",
      "                \"title\": \"Chinook salmon\",\n",
      "                \"contentmodel\": \"wikitext\",\n",
      "                \"pagelanguage\": \"en\",\n",
      "                \"pagelanguagehtmlcode\": \"en\",\n",
      "                \"pagelanguagedir\": \"ltr\",\n",
      "                \"touched\": \"2024-10-12T10:13:54Z\",\n",
      "                \"lastrevid\": 1234351318,\n",
      "                \"length\": 53787,\n",
      "                \"watchers\": 109,\n",
      "                \"talkid\": 3909817,\n",
      "                \"fullurl\": \"https://en.wikipedia.org/wiki/Chinook_salmon\",\n",
      "                \"editurl\": \"https://en.wikipedia.org/w/index.php?title=Chinook_salmon&action=edit\",\n",
      "                \"canonicalurl\": \"https://en.wikipedia.org/wiki/Chinook_salmon\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Getting page info data for: {ARTICLE_TITLES[3]}\")\n",
    "info = request_pageinfo_per_article(ARTICLE_TITLES[3])\n",
    "print(json.dumps(info,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requesting ORES scores through LiftWing ML Service API\n",
    "\n",
    "This sub-section illustrates how to generate article quality estimates for article revisions using the LiftWing version of ORES. The ORES API documentation can be accessed from the main ORES page. The ORES LiftWing documentation is very thin ... even thinner than the standard ORES documentation. Further, it is clear that some parameters have been renamed (e.g., \"revid\" in the old ORES API is now \"rev_id\" in the LiftWing ORES API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "This code example was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). \n",
    "\n",
    "Modifications to this code were made by Himanshu Naidu on October 13, 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "#    The current LiftWing ORES API endpoint and prediction model\n",
    "#\n",
    "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\n",
    "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\n",
    "\n",
    "#\n",
    "#    The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
    "#    come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\n",
    "#\n",
    "API_ORES_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_ORES_THROTTLE_WAIT = ((60.0*60.0)/5000.0)-API_ORES_LATENCY_ASSUMED  # The key authorizes 5000 requests per hour\n",
    "\n",
    "#    When making automated requests we should include something that is unique to the person making the request\n",
    "#    This should include an email - your UW email would be good to put in there\n",
    "#    \n",
    "#    Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
    "#    as part of the header too\n",
    "#\n",
    "REQUEST_HEADER_TEMPLATE = {\n",
    "    'User-Agent': \"<{email_address}>, University of Washington, MSDS DATA 512 - AUTUMN 2024\",\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': \"Bearer {access_token}\"\n",
    "}\n",
    "#\n",
    "#    This is a template for the parameters that we need to supply in the headers of an API request\n",
    "#\n",
    "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
    "    'email_address' : \"\",         # your email address should go here\n",
    "    'access_token'  : \"\"          # the access token you create will need to go here\n",
    "}\n",
    "\n",
    "#\n",
    "#    A dictionary of English Wikipedia article titles (keys) and sample revision IDs that can be used for this ORES scoring example\n",
    "#\n",
    "ARTICLE_REVISIONS = { 'Bison':1085687913 , 'Northern flicker':1086582504 , 'Red squirrel':1083787665 , 'Chinook salmon':1085406228 , 'Horseshoe bat':1060601936 }\n",
    "\n",
    "#\n",
    "#    This is a template of the data required as a payload when making a scoring request of the ORES model\n",
    "#\n",
    "ORES_REQUEST_DATA_TEMPLATE = {\n",
    "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
    "    \"rev_id\":      \"\",       # this request requires a revision id\n",
    "    \"features\":    True\n",
    "}\n",
    "\n",
    "#\n",
    "#    These are used later - defined here so they, at least, have empty values\n",
    "#\n",
    "USERNAME = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your access token\n",
    "\n",
    "You will need a Wikimedia user account to get access to Lift Wing (the ML API service). You can either [create an account or login](https://api.wikimedia.org/w/index.php?title=Special:UserLogin). If you have a Wikipedia user account - you might already have an Wikimedia account. If you are not sure try your Wikipedia username and password to check it. If you do not have a Wikimedia account you will need to create an account that you can use to get an access token.\n",
    "\n",
    "There is [a 'guide' that describes how to get authentication tokens](https://api.wikimedia.org/wiki/Authentication) - but not everything works the way it is described in that documentation. You should review that documentation and then read the rest of this comment.\n",
    "\n",
    "The documentation talks about using a \"dashboard\" for managing authentication tokens. That's a rather generous description for what looks like a simple list of token things. You might have a hard time finding this \"dashboard\". First, on the left hand side of the page, you'll see a column of links. The bottom section is a set of links titled \"Tools\". In that section is a link that says [Special pages](https://api.wikimedia.org/wiki/Special:SpecialPages) which will take you to a list of ... well, special pages. At the very bottom of the \"Special pages\" page is a section titled \"Other special pages\" (scroll all the way to the bottom). The first link in that section is called [API keys](https://api.wikimedia.org/wiki/Special:AppManagement). When you get to the \"API keys\" page you can create a new key.\n",
    "\n",
    "The authentication guide suggests that you should create a server-side app key. This does not seem to work correctly - as yet. It failed on multiple attempts when I attempted to create a server-side app key. BUT, there is an option to create a [Personal API token](https://api.wikimedia.org/wiki/Authentication) that should work for this course and the type of ORES page scoring that you will need to perform.\n",
    "\n",
    "Note, when you create a Personal API token you are granted the three items - a Client ID, a Client secret, and a Access token - you shold save all three of these. When you dismiss the box they are gone. If you lose any one of the tokens you can destroy or deactivate the Personal API token from the dashboard and then create a new one.\n",
    "\n",
    "The value you need to work the code below is the Access token - a very long string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Once you've done the right set up with your Wikimedia account, it should provide you with three different keys, a Client ID,\n",
    "#   a Client secret, and a Access token.\n",
    "#\n",
    "#   In this case I don't want to distribute my keys with the source of the notebook, so I used the dotenv package to load them from\n",
    "#   a file called '.env' in the same directory as this notebook. The file should look like this:\n",
    "#\n",
    "#   WIKIMEDIA_USERNAME=\"<your_wikimedia_username>\"\n",
    "#   WIKIMEDIA_CLIENT_ID=\"<your_wikimedia_client_id>\"\n",
    "#   WIKIMEDIA_CLIENT_SECRET=\"<your_wikimedia_client_secret>\"\n",
    "#   WIKIMEDIA_ACCESS_TOKEN=\"<your_wikimedia_provided_access_token_its_a_really_long_string>\"\n",
    "#\n",
    "#   The repository has a file called '.env.example' that you can copy to '.env' and fill in the values.\n",
    "\n",
    "# USERNAME = \"<your_wikimedia_username>\"\n",
    "# ACCESS_TOKEN = \"<your_wikimedia_provided_access_token_its_a_really_long_string>\"\n",
    "\n",
    "# Note: The above properties will be assigned in the \"Getting Article Quality Predictions\" section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to make the ORES API request\n",
    "\n",
    "The API request will be made using a function to encapsulate call and make access reusable in other notebooks. The procedure is parameterized, relying on the constants above for some important default parameters. The primary assumption is that this function will be used to request data for a set of article revisions. The main parameter is 'article_revid'. One should be able to simply pass in a new article revision id on each call and get back a python dictionary as the result. A valid result will be a dictionary that contains the probabilities that the specific revision is one of six different article quality levels. Generally, quality level with the highest probability score is considered the quality level for the article. This can be tricky when you have two (or more) highly probable quality levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\n",
    "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT, \n",
    "                                   model_name = API_ORES_EN_QUALITY_MODEL, \n",
    "                                   request_data = ORES_REQUEST_DATA_TEMPLATE, \n",
    "                                   header_format = REQUEST_HEADER_TEMPLATE, \n",
    "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\n",
    "    \n",
    "    #    Make sure we have an article revision id, email and token\n",
    "    #    This approach prioritizes the parameters passed in when making the call\n",
    "    if article_revid:\n",
    "        request_data['rev_id'] = article_revid\n",
    "    if email_address:\n",
    "        header_params['email_address'] = email_address\n",
    "    if access_token:\n",
    "        header_params['access_token'] = access_token\n",
    "    \n",
    "    #   Making a request requires a revision id - an email address - and the access token\n",
    "    if not request_data['rev_id']:\n",
    "        raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\n",
    "    if not header_params['email_address']:\n",
    "        raise Exception(\"Must provide an 'email_address' value\")\n",
    "    if not header_params['access_token']:\n",
    "        raise Exception(\"Must provide an 'access_token' value\")\n",
    "    \n",
    "    # Create the request URL with the specified model parameter - default is a article quality score request\n",
    "    request_url = endpoint_url.format(model_name=model_name)\n",
    "    \n",
    "    # Create a compliant request header from the template and the supplied parameters\n",
    "    headers = dict()\n",
    "    for key in header_format.keys():\n",
    "        headers[str(key)] = header_format[key].format(**header_params)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free data\n",
    "        # source like ORES - or other community sources\n",
    "        if API_ORES_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_ORES_THROTTLE_WAIT)\n",
    "        #response = requests.get(request_url, headers=headers)\n",
    "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Article and Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    IMPORTS\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "# Dev environment flag to control the number of requests made to the API for testing\n",
    "DEV_ENVIRONMENT = False\n",
    "\n",
    "# The cleaned CSV file path that contains the list of politicians by country\n",
    "POLITICIANS_BY_COUNTRY_CSV_PATH = \"politicians_by_country_AUG.2024.csv\"\n",
    "# The cleaned CSV file path that contains the list of population by country\n",
    "POPULATION_BY_COUNTRY_CSV_PATH = \"population_by_country_AUG.2024.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in the [MediaWiki REST API Help](https://www.mediawiki.org/w/api.php?action=help&modules=query): \n",
    "\n",
    "For titles \"Maximum number of values is 50 (500 for clients that are allowed higher limits).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be on the safe side, we'll limit the number of titles to 40\n",
    "TITLE_LIMIT = 40\n",
    "# The separator for the titles in the query string\n",
    "TITLE_SEPARATOR = \"|\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the error list file, that includes the articles whose page info could not be retrieved\n",
    "PAGE_INFO_ERROR_LIST_PATH = \"data/page_info_errors.txt\"\n",
    "# The path to the output file that contains the page info data\n",
    "WP_POLITICIANS_WITH_PAGE_INFO_PATH = \"data/wp_politicians_with_page_info.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a way to get the page information for multiple pages at the same time, by separating the page titles with the vertical bar \"|\" character. However, this approach has limits. You should probably check the API documentation if you want to do multiple pages in a single request - and limit the number of pages in one request reasonably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_page_info_multiple_articles(titles = None, title_sep = '|', error_list = None):\n",
    "    '''\n",
    "    This function takes a list of article titles and returns the page information for all the articles in a list.\n",
    "    This function also adds the titles that could not be fetched to the error list.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    titles : str\n",
    "        A string of article titles separated by a delimiter\n",
    "\n",
    "    title_sep : str\n",
    "        The delimiter that separates the article titles in the string\n",
    "\n",
    "    error_list : list\n",
    "        A list to store the titles that could not be fetched\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    page_info_list : list\n",
    "        A list of dictionaries containing the page information for each article\n",
    "    '''\n",
    "    page_info_list = []\n",
    "    page_info = None\n",
    "\n",
    "    if titles is None:\n",
    "        titles = \"\"\n",
    "    if error_list is None:\n",
    "        error_list = []\n",
    "    try:\n",
    "        json_response = request_pageinfo_per_article(titles)\n",
    "\n",
    "        page_info_dict = json_response['query']['pages']\n",
    "        for page_id, page_info in page_info_dict.items():\n",
    "            try:\n",
    "                page_info_list.append({\n",
    "                    \"page_id\": page_info[\"pageid\"],\n",
    "                    \"title\": page_info[\"title\"],\n",
    "                    \"revision_id\": page_info[\"lastrevid\"],\n",
    "                    \"page_length\": page_info[\"length\"],\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(\"Error while fetching data for: \", page_info[\"title\"])\n",
    "                error_list.append(page_info[\"title\"])\n",
    "                print(e)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error in API while fetching data\")\n",
    "        error_list.extend(titles.split(title_sep))\n",
    "        print(e)\n",
    "    \n",
    "    return page_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(file_path, list_to_write):\n",
    "    '''\n",
    "    This function writes a list to a file.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    file_path : str\n",
    "        The path of the file to write the list to\n",
    "    \n",
    "    list_to_write : list\n",
    "        The list to write to the file\n",
    "    '''\n",
    "    with open(file_path, 'w') as file:\n",
    "        for item in list_to_write:\n",
    "            file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Politicians Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned CSV file that contains the list of politicians by country\n",
    "politicians_by_country_df = pd.read_csv(POLITICIANS_BY_COUNTRY_CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The following loop was executed on a system equipped with a 12th Gen Intel® Core™ i7-12700H processor (2.30 GHz). The total execution time for this loop was under 2 minutes\n",
    "\n",
    "The results have already been saved in WP_POLITICIANS_WITH_PAGE_INFO_PATH. \n",
    "\n",
    "Skip the next 3 cells to directly utilize the data saved in WP_POLITICIANS_WITH_PAGE_INFO_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hnaidu36/miniforge3/envs/data512/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while fetching data for:  Barbara Eibinger-Miedl\n",
      "'pageid'\n",
      "Error while fetching data for:  Mehrali Gasimov\n",
      "'pageid'\n",
      "Error while fetching data for:  Kyaw Myint\n",
      "'pageid'\n",
      "Error while fetching data for:  André Ngongang Ouandji\n",
      "'pageid'\n",
      "Error while fetching data for:  Tomás Pimentel\n",
      "'pageid'\n",
      "Error while fetching data for:  Richard Sumah\n",
      "'pageid'\n",
      "Error while fetching data for:  Segun ''Aeroland'' Adewale\n",
      "'pageid'\n",
      "Error while fetching data for:  Bashir Bililiqo\n",
      "'pageid'\n"
     ]
    }
   ],
   "source": [
    "page_info_list = []\n",
    "page_info_error_list = []\n",
    "total_len = 0\n",
    "\n",
    "# Get the page info in batches of TITLE_LIMIT\n",
    "# The function np.array_split splits the dataframe into batches of TITLE_LIMIT or TITLE_LIMIT + 1\n",
    "# Hence, we use a TITLE_LIMIT that is less than the actual limit to avoid making a bigger request than the limit\n",
    "for batch in np.array_split(politicians_by_country_df, len(politicians_by_country_df) // TITLE_LIMIT):\n",
    "    titles = batch[\"name\"].tolist()\n",
    "    page_info_list_batch = request_page_info_multiple_articles(TITLE_SEPARATOR.join(titles), TITLE_SEPARATOR, page_info_error_list)\n",
    "    page_info_list.extend(page_info_list_batch)\n",
    "\n",
    "page_info_df = pd.DataFrame(page_info_list)\n",
    "\n",
    "# Write the error list to a file\n",
    "write_list_to_file(PAGE_INFO_ERROR_LIST_PATH, page_info_error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, there are duplicates in the politicians_by_country_df dataframe. We'll drop the duplicates in the page_info_df dataframe, and keep the first occurrence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7103, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_info_df = page_info_df.drop_duplicates(subset=['page_id'])\n",
    "page_info_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the final page_info dataframe to a CSV file\n",
    "page_info_df.to_csv(WP_POLITICIANS_WITH_PAGE_INFO_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data in case the above data extraction is skipped.\n",
    "page_info_df = pd.read_csv(WP_POLITICIANS_WITH_PAGE_INFO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>page_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27428272</td>\n",
       "      <td>Abdul Baqi Turkistani</td>\n",
       "      <td>1231655023</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29443640</td>\n",
       "      <td>Abdul Ghani Ghani</td>\n",
       "      <td>1227026187</td>\n",
       "      <td>1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44482763</td>\n",
       "      <td>Abdul Rahim Ayoubi</td>\n",
       "      <td>1226326055</td>\n",
       "      <td>7313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52438668</td>\n",
       "      <td>Aimal Faizi</td>\n",
       "      <td>1185105938</td>\n",
       "      <td>2791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12084570</td>\n",
       "      <td>Amir Muhammad Akhundzada</td>\n",
       "      <td>1247931713</td>\n",
       "      <td>8865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_id                     title  revision_id  page_length\n",
       "0  27428272     Abdul Baqi Turkistani   1231655023         1357\n",
       "1  29443640         Abdul Ghani Ghani   1227026187         1292\n",
       "2  44482763        Abdul Rahim Ayoubi   1226326055         7313\n",
       "3  52438668               Aimal Faizi   1185105938         2791\n",
       "4  12084570  Amir Muhammad Akhundzada   1247931713         8865"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Info Error Rate: 0.11250175783996674%\n"
     ]
    }
   ],
   "source": [
    "# Calculate Error Rate\n",
    "TOTAL_POLITICIAN_ARTICLES = politicians_by_country_df['name'].nunique()\n",
    "TOTAL_PAGE_INFO_ARTICLES = page_info_df['page_id'].nunique()\n",
    "\n",
    "page_info_error_rate = 1 - (TOTAL_PAGE_INFO_ARTICLES / TOTAL_POLITICIAN_ARTICLES)\n",
    "print(f\"Page Info Error Rate: {page_info_error_rate * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Article Quality Predictions\n",
    "\n",
    "Once the latest revision ids are extracted for each article, using the Page Info API, the ORES API can be used to get the Quality Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    IMPORTS\n",
    "#\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The path to the .env file that contains the Wikimedia credentials\n",
    "ENV_PATH = \".env\"\n",
    "\n",
    "ORES_ERROR_LIST_PATH = \"data/ores_errors.txt\"\n",
    "\n",
    "# The path to the output file that contains the ORES scores\n",
    "WP_POLITICIANS_WITH_ORES_PATH = \"data/wp_politicians_with_ores.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(ENV_PATH)\n",
    "\n",
    "USERNAME = os.getenv(\"WIKIMEDIA_USERNAME\")\n",
    "ACCESS_TOKEN = os.getenv(\"WIKIMEDIA_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the ORES API\n",
    "\n",
    "Note: The following loop was executed on a system equipped with a 12th Gen Intel® Core™ i7-12700H processor (2.30 GHz). The total execution time for this loop was 141 minutes and 44 seconds.\n",
    "\n",
    "The results have already been saved in WP_POLITICIANS_WITH_ORES_PATH. \n",
    "\n",
    "Skip the next 3 cells to directly utilize the data saved in WP_POLITICIANS_WITH_ORES_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ores_quality_prediction_list = []\n",
    "ores_quality_prediction_error_list = []\n",
    "\n",
    "\n",
    "for index,row in tqdm(page_info_df.iterrows(), total=page_info_df.shape[0]):\n",
    "    try:\n",
    "        article_score_json_response = request_ores_score_per_article(article_revid=row[\"revision_id\"],\n",
    "                                           email_address=USER_EMAIL,\n",
    "                                           access_token=ACCESS_TOKEN)\n",
    "        \n",
    "        article_scores = article_score_json_response[\"enwiki\"][\"scores\"][f'{row[\"revision_id\"]}']\n",
    "        article_quality_prediction = article_scores[\"articlequality\"][\"score\"][\"prediction\"]\n",
    "    \n",
    "        row_dict = row.to_dict()\n",
    "        row_dict[\"article_quality_prediction\"] = article_quality_prediction\n",
    "        ores_quality_prediction_list.append(row_dict)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error fetching quality prediction for\", row[\"title\"], \", Revision:\", row[\"revision_id\"])\n",
    "        print(e)\n",
    "        ores_quality_prediction_error_list.append(row[\"title\"])\n",
    "\n",
    "    if DEV_ENVIRONMENT and index > 5:\n",
    "        break\n",
    "\n",
    "ores_quality_prediction_df = pd.DataFrame(ores_quality_prediction_list)\n",
    "\n",
    "# Write the error list to a file\n",
    "write_list_to_file(ORES_ERROR_LIST_PATH, ores_quality_prediction_error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7102, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ores_quality_prediction_df = ores_quality_prediction_df.drop_duplicates(subset=['page_id'])\n",
    "ores_quality_prediction_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the final ORES quality prediction dataframe to a CSV file\n",
    "ores_quality_prediction_df.to_csv(WP_POLITICIANS_WITH_ORES_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data in case the above data extraction is skipped.\n",
    "ores_quality_prediction_df = pd.read_csv(WP_POLITICIANS_WITH_ORES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>page_length</th>\n",
       "      <th>article_quality_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27428272</td>\n",
       "      <td>Abdul Baqi Turkistani</td>\n",
       "      <td>1231655023</td>\n",
       "      <td>1357</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29443640</td>\n",
       "      <td>Abdul Ghani Ghani</td>\n",
       "      <td>1227026187</td>\n",
       "      <td>1292</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44482763</td>\n",
       "      <td>Abdul Rahim Ayoubi</td>\n",
       "      <td>1226326055</td>\n",
       "      <td>7313</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52438668</td>\n",
       "      <td>Aimal Faizi</td>\n",
       "      <td>1185105938</td>\n",
       "      <td>2791</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12084570</td>\n",
       "      <td>Amir Muhammad Akhundzada</td>\n",
       "      <td>1247931713</td>\n",
       "      <td>8865</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_id                     title  revision_id  page_length  \\\n",
       "0  27428272     Abdul Baqi Turkistani   1231655023         1357   \n",
       "1  29443640         Abdul Ghani Ghani   1227026187         1292   \n",
       "2  44482763        Abdul Rahim Ayoubi   1226326055         7313   \n",
       "3  52438668               Aimal Faizi   1185105938         2791   \n",
       "4  12084570  Amir Muhammad Akhundzada   1247931713         8865   \n",
       "\n",
       "  article_quality_prediction  \n",
       "0                       Stub  \n",
       "1                       Stub  \n",
       "2                      Start  \n",
       "3                       Stub  \n",
       "4                      Start  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ores_quality_prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORES Error Rate: 0.12656447756995703%\n"
     ]
    }
   ],
   "source": [
    "# Calculate Error Rate\n",
    "TOTAL_POLITICIAN_ARTICLES = politicians_by_country_df['name'].nunique()\n",
    "TOTAL_ORES_PREDICTIONS = ores_quality_prediction_df['page_id'].nunique()\n",
    "\n",
    "ores_error_rate = 1 - (TOTAL_ORES_PREDICTIONS / TOTAL_POLITICIAN_ARTICLES)\n",
    "print(f\"ORES Error Rate: {ores_error_rate * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "COUNTRIES_NO_MATCH_PATH = \"data/wp_countries-no_match.txt\"\n",
    "POLITICIANS_BY_COUNTRY_PATH = \"data/wp_politicians_by_country.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Population and Region Details\n",
    "\n",
    "We now set up dataframes that contain population details of countries and regions. This will be matched with articles through the countries that they (the respective politicians) belong to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WORLD</td>\n",
       "      <td>8009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>1453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>46.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>105.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Geography  Population\n",
       "0            WORLD      8009.0\n",
       "1           AFRICA      1453.0\n",
       "2  NORTHERN AFRICA       256.0\n",
       "3          Algeria        46.8\n",
       "4            Egypt       105.2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned CSV file that contains the list of population by country\n",
    "population_by_country_df = pd.read_csv(POPULATION_BY_COUNTRY_CSV_PATH)\n",
    "population_by_country_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population_by_country_AUG.2024.csv represents regions in a hierarchical order. Thus, to get the region that a country belongs to, we simply have to put a country into the closest (lowest in the hierarchy) region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_region = None\n",
    "\n",
    "population_by_country_region_list = []\n",
    "\n",
    "for index, row in population_by_country_df.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    if row[\"Geography\"].isupper():\n",
    "        current_region = row[\"Geography\"]\n",
    "        row_dict[\"region\"] = \"\"\n",
    "    else:\n",
    "        row_dict[\"region\"] = current_region\n",
    "    population_by_country_region_list.append(row_dict)\n",
    "\n",
    "population_by_country_region_df = pd.DataFrame(population_by_country_region_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of countries in the population dataset: 209\n"
     ]
    }
   ],
   "source": [
    "# Rename the columns 'Geography' and 'Population' to 'country' and 'population' respectively\n",
    "population_by_country_region_df.rename(columns={\"Geography\": \"country\", \"Population\": \"population\"}, inplace=True)\n",
    "# Remove the rows with 'region' as empty\n",
    "population_by_country_region_df = population_by_country_region_df[population_by_country_region_df[\"region\"] != \"\"]\n",
    "\n",
    "print(\"Total number of countries in the population dataset:\", population_by_country_region_df[\"country\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>46.8</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>105.2</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Libya</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Morocco</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sudan</td>\n",
       "      <td>48.1</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  population           region\n",
       "3  Algeria        46.8  NORTHERN AFRICA\n",
       "4    Egypt       105.2  NORTHERN AFRICA\n",
       "5    Libya         6.9  NORTHERN AFRICA\n",
       "6  Morocco        37.0  NORTHERN AFRICA\n",
       "7    Sudan        48.1  NORTHERN AFRICA"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_by_country_region_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Country-Wise\n",
    "\n",
    "Merge the relevant data frames to finally have a data frame that contains details of each article, including the ORES API quality prediction, the respective country (along with population) and the respective region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>page_length</th>\n",
       "      <th>article_quality_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27428272</td>\n",
       "      <td>Abdul Baqi Turkistani</td>\n",
       "      <td>1231655023</td>\n",
       "      <td>1357</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29443640</td>\n",
       "      <td>Abdul Ghani Ghani</td>\n",
       "      <td>1227026187</td>\n",
       "      <td>1292</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44482763</td>\n",
       "      <td>Abdul Rahim Ayoubi</td>\n",
       "      <td>1226326055</td>\n",
       "      <td>7313</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52438668</td>\n",
       "      <td>Aimal Faizi</td>\n",
       "      <td>1185105938</td>\n",
       "      <td>2791</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12084570</td>\n",
       "      <td>Amir Muhammad Akhundzada</td>\n",
       "      <td>1247931713</td>\n",
       "      <td>8865</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_id                     title  revision_id  page_length  \\\n",
       "0  27428272     Abdul Baqi Turkistani   1231655023         1357   \n",
       "1  29443640         Abdul Ghani Ghani   1227026187         1292   \n",
       "2  44482763        Abdul Rahim Ayoubi   1226326055         7313   \n",
       "3  52438668               Aimal Faizi   1185105938         2791   \n",
       "4  12084570  Amir Muhammad Akhundzada   1247931713         8865   \n",
       "\n",
       "  article_quality_prediction  \n",
       "0                       Stub  \n",
       "1                       Stub  \n",
       "2                      Start  \n",
       "3                       Stub  \n",
       "4                      Start  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ores_quality_prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Majah_Ha_Adrif</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Haroon_al-Afghani</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tayyab_Agha</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khadija Zahra Ahmadi</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aziza Ahmadyar</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aziza_Ahmadyar</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                                url  \\\n",
       "0        Majah Ha Adrif       https://en.wikipedia.org/wiki/Majah_Ha_Adrif   \n",
       "1     Haroon al-Afghani    https://en.wikipedia.org/wiki/Haroon_al-Afghani   \n",
       "2           Tayyab Agha          https://en.wikipedia.org/wiki/Tayyab_Agha   \n",
       "3  Khadija Zahra Ahmadi  https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...   \n",
       "4        Aziza Ahmadyar       https://en.wikipedia.org/wiki/Aziza_Ahmadyar   \n",
       "\n",
       "       country  \n",
       "0  Afghanistan  \n",
       "1  Afghanistan  \n",
       "2  Afghanistan  \n",
       "3  Afghanistan  \n",
       "4  Afghanistan  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politicians_by_country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality_prediction</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27428272</td>\n",
       "      <td>Abdul Baqi Turkistani</td>\n",
       "      <td>1231655023</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29443640</td>\n",
       "      <td>Abdul Ghani Ghani</td>\n",
       "      <td>1227026187</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44482763</td>\n",
       "      <td>Abdul Rahim Ayoubi</td>\n",
       "      <td>1226326055</td>\n",
       "      <td>Start</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52438668</td>\n",
       "      <td>Aimal Faizi</td>\n",
       "      <td>1185105938</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12084570</td>\n",
       "      <td>Amir Muhammad Akhundzada</td>\n",
       "      <td>1247931713</td>\n",
       "      <td>Start</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_id                     title  revision_id article_quality_prediction  \\\n",
       "0  27428272     Abdul Baqi Turkistani   1231655023                       Stub   \n",
       "1  29443640         Abdul Ghani Ghani   1227026187                       Stub   \n",
       "2  44482763        Abdul Rahim Ayoubi   1226326055                      Start   \n",
       "3  52438668               Aimal Faizi   1185105938                       Stub   \n",
       "4  12084570  Amir Muhammad Akhundzada   1247931713                      Start   \n",
       "\n",
       "       country  \n",
       "0  Afghanistan  \n",
       "1  Afghanistan  \n",
       "2  Afghanistan  \n",
       "3  Afghanistan  \n",
       "4  Afghanistan  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the ores_quality_prediction_df with politicians_by_country_df to get the country for each article\n",
    "# The merge needs to be done on ores_quality_prediction_df 'title' and politicians_by_country_df 'name' columns\n",
    "ores_quality_prediction_country_df = \\\n",
    "    pd.merge(ores_quality_prediction_df, politicians_by_country_df, left_on='title', right_on='name', how='inner')\n",
    "ores_quality_prediction_country_df.drop(columns=['name', 'url', 'page_length'], inplace=True)\n",
    "ores_quality_prediction_country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct some country names in population_by_country_region_df to match the country names in ores_quality_prediction_country_df\n",
    "corrections = {\n",
    "    \"GuineaBissau\": \"Guinea-Bissau\",\n",
    "    \"Korea (South)\": \"Korea, South\"\n",
    "}\n",
    "\n",
    "population_by_country_region_df[\"country\"] = population_by_country_region_df[\"country\"].replace(corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality_prediction</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>region</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27428272.0</td>\n",
       "      <td>Abdul Baqi Turkistani</td>\n",
       "      <td>1.231655e+09</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29443640.0</td>\n",
       "      <td>Abdul Ghani Ghani</td>\n",
       "      <td>1.227026e+09</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44482763.0</td>\n",
       "      <td>Abdul Rahim Ayoubi</td>\n",
       "      <td>1.226326e+09</td>\n",
       "      <td>Start</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52438668.0</td>\n",
       "      <td>Aimal Faizi</td>\n",
       "      <td>1.185106e+09</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12084570.0</td>\n",
       "      <td>Amir Muhammad Akhundzada</td>\n",
       "      <td>1.247932e+09</td>\n",
       "      <td>Start</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      page_id                     title   revision_id  \\\n",
       "0  27428272.0     Abdul Baqi Turkistani  1.231655e+09   \n",
       "1  29443640.0         Abdul Ghani Ghani  1.227026e+09   \n",
       "2  44482763.0        Abdul Rahim Ayoubi  1.226326e+09   \n",
       "3  52438668.0               Aimal Faizi  1.185106e+09   \n",
       "4  12084570.0  Amir Muhammad Akhundzada  1.247932e+09   \n",
       "\n",
       "  article_quality_prediction      country  population      region _merge  \n",
       "0                       Stub  Afghanistan        42.4  SOUTH ASIA   both  \n",
       "1                       Stub  Afghanistan        42.4  SOUTH ASIA   both  \n",
       "2                      Start  Afghanistan        42.4  SOUTH ASIA   both  \n",
       "3                       Stub  Afghanistan        42.4  SOUTH ASIA   both  \n",
       "4                      Start  Afghanistan        42.4  SOUTH ASIA   both  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the ores_quality_prediction_country_df with population_by_country_region_df to get the population and region for each article\n",
    "# The merge needs to be done on ores_quality_prediction_country_df 'country' and population_by_country_region_df 'country' columns\n",
    "# The merge will be outer, to eventually identify entries that did not merge correctly\n",
    "ores_quality_prediction_country_population_df = \\\n",
    "    pd.merge(ores_quality_prediction_country_df, population_by_country_region_df, on='country', how='outer', indicator=True)\n",
    "ores_quality_prediction_country_population_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with no population info:\n",
      " ['Korean']\n"
     ]
    }
   ],
   "source": [
    "# Identify all countries for which there are invalid merges\n",
    "country_no_match_list1 = ores_quality_prediction_country_population_df[ores_quality_prediction_country_population_df[\"_merge\"] == \"left_only\"][\"country\"].unique()\n",
    "print(\"Countries with no population info:\\n\", country_no_match_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries in the population dataset do not have articles:\n",
      " ['Andorra' 'Australia' 'Brunei' 'Canada' 'China (Hong Kong SAR)'\n",
      " 'China (Macao SAR)' 'Curacao' 'Denmark' 'Dominica' 'Fiji' 'French Guiana'\n",
      " 'French Polynesia' 'Georgia' 'Guadeloupe' 'Guam' 'Iceland' 'Ireland'\n",
      " 'Jamaica' 'Kiribati' 'Korea (North)' 'Liechtenstein' 'Martinique'\n",
      " 'Mauritius' 'Mayotte' 'Mexico' 'Nauru' 'Netherlands' 'New Caledonia'\n",
      " 'New Zealand' 'Palau' 'Philippines' 'Puerto Rico' 'Reunion' 'Romania'\n",
      " 'San Marino' 'Sao Tome and Principe' 'Suriname' 'United Kingdom'\n",
      " 'United States' 'Western Sahara' 'eSwatini']\n"
     ]
    }
   ],
   "source": [
    "# Identify all politicians for which there are invalid merges\n",
    "country_no_match_list2 = ores_quality_prediction_country_population_df[ores_quality_prediction_country_population_df[\"_merge\"] == \"right_only\"][\"country\"].unique()\n",
    "print(\"Countries in the population dataset do not have articles:\\n\", country_no_match_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_no_match_list = list(set(country_no_match_list1) | set(country_no_match_list2))\n",
    "write_list_to_file(COUNTRIES_NO_MATCH_PATH, country_no_match_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2123/2413107538.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wp_politicians_by_country_df.drop(columns=[\"_merge\"], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality_prediction</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27428272.0</td>\n",
       "      <td>Abdul Baqi Turkistani</td>\n",
       "      <td>1.231655e+09</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29443640.0</td>\n",
       "      <td>Abdul Ghani Ghani</td>\n",
       "      <td>1.227026e+09</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44482763.0</td>\n",
       "      <td>Abdul Rahim Ayoubi</td>\n",
       "      <td>1.226326e+09</td>\n",
       "      <td>Start</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52438668.0</td>\n",
       "      <td>Aimal Faizi</td>\n",
       "      <td>1.185106e+09</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12084570.0</td>\n",
       "      <td>Amir Muhammad Akhundzada</td>\n",
       "      <td>1.247932e+09</td>\n",
       "      <td>Start</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      page_id                     title   revision_id  \\\n",
       "0  27428272.0     Abdul Baqi Turkistani  1.231655e+09   \n",
       "1  29443640.0         Abdul Ghani Ghani  1.227026e+09   \n",
       "2  44482763.0        Abdul Rahim Ayoubi  1.226326e+09   \n",
       "3  52438668.0               Aimal Faizi  1.185106e+09   \n",
       "4  12084570.0  Amir Muhammad Akhundzada  1.247932e+09   \n",
       "\n",
       "  article_quality_prediction      country  population      region  \n",
       "0                       Stub  Afghanistan        42.4  SOUTH ASIA  \n",
       "1                       Stub  Afghanistan        42.4  SOUTH ASIA  \n",
       "2                      Start  Afghanistan        42.4  SOUTH ASIA  \n",
       "3                       Stub  Afghanistan        42.4  SOUTH ASIA  \n",
       "4                      Start  Afghanistan        42.4  SOUTH ASIA  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, drop the rows that did not merge correctly to get the final dataframe\n",
    "wp_politicians_by_country_df = \\\n",
    "    ores_quality_prediction_country_population_df[ores_quality_prediction_country_population_df[\"_merge\"] == \"both\"]\n",
    "wp_politicians_by_country_df.drop(columns=[\"_merge\"], inplace=True)\n",
    "wp_politicians_by_country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the final dataframe to a CSV file\n",
    "wp_politicians_by_country_df.to_csv(POLITICIANS_BY_COUNTRY_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Results\n",
    "\n",
    "Analysis 1: \n",
    "\n",
    "Top 10 countries by coverage: The 10 countries with the highest total articles per capita (in descending order) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 countries by coverage (descending):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>total_articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>33</td>\n",
       "      <td>330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Federated States of Micronesia</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>0.1</td>\n",
       "      <td>14</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Tonga</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Barbados</td>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Seychelles</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Montenegro</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>0.6</td>\n",
       "      <td>36</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Maldives</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>0.6</td>\n",
       "      <td>33</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            country           region  population  \\\n",
       "156                          Tuvalu          OCEANIA         0.0   \n",
       "98                           Monaco   WESTERN EUROPE         0.0   \n",
       "4               Antigua and Barbuda        CARIBBEAN         0.1   \n",
       "51   Federated States of Micronesia          OCEANIA         0.1   \n",
       "95                 Marshall Islands          OCEANIA         0.1   \n",
       "151                           Tonga          OCEANIA         0.1   \n",
       "12                         Barbados        CARIBBEAN         0.3   \n",
       "127                      Seychelles   EASTERN AFRICA         0.1   \n",
       "100                      Montenegro  SOUTHERN EUROPE         0.6   \n",
       "92                         Maldives       SOUTH ASIA         0.6   \n",
       "\n",
       "     total_articles  total_articles_per_capita  \n",
       "156               1                        inf  \n",
       "98               10                        inf  \n",
       "4                33                 330.000000  \n",
       "51               14                 140.000000  \n",
       "95               13                 130.000000  \n",
       "151              10                 100.000000  \n",
       "12               25                  83.333333  \n",
       "127               6                  60.000000  \n",
       "100              36                  60.000000  \n",
       "92               33                  55.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 countries by coverage: The 10 countries with the highest total articles per capita (in descending order) .\n",
    "top_10_countries_by_coverage = wp_politicians_by_country_df.groupby([\"country\", \"region\", \"population\"]).size().reset_index(name='total_articles')\n",
    "top_10_countries_by_coverage[\"total_articles_per_capita\"] = top_10_countries_by_coverage[\"total_articles\"] / top_10_countries_by_coverage[\"population\"]\n",
    "\n",
    "top_10_countries_by_coverage.sort_values(by=\"total_articles_per_capita\", ascending=False, inplace=True)\n",
    "print(\"Top 10 countries by coverage (descending):\")\n",
    "top_10_countries_by_coverage.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis 2:\n",
    "\n",
    "Bottom 10 countries by coverage: The 10 countries with the lowest total articles per capita (in ascending order) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 10 countries by coverage (ascending):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>total_articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>China</td>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>1411.3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.011337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Ghana</td>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>34.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.087977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>India</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>1428.6</td>\n",
       "      <td>151</td>\n",
       "      <td>0.105698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>36.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.135501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>20.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.148515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Norway</td>\n",
       "      <td>NORTHERN EUROPE</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Israel</td>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>105.2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.304183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Cote d'Ivoire</td>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>30.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.323625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>126.5</td>\n",
       "      <td>44</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country           region  population  total_articles  \\\n",
       "31           China        EAST ASIA      1411.3              16   \n",
       "57           Ghana   WESTERN AFRICA        34.1               3   \n",
       "67           India       SOUTH ASIA      1428.6             151   \n",
       "124   Saudi Arabia     WESTERN ASIA        36.9               5   \n",
       "166         Zambia   EASTERN AFRICA        20.2               3   \n",
       "110         Norway  NORTHERN EUROPE         5.5               1   \n",
       "71          Israel     WESTERN ASIA         9.8               2   \n",
       "45           Egypt  NORTHERN AFRICA       105.2              32   \n",
       "37   Cote d'Ivoire   WESTERN AFRICA        30.9              10   \n",
       "50        Ethiopia   EASTERN AFRICA       126.5              44   \n",
       "\n",
       "     total_articles_per_capita  \n",
       "31                    0.011337  \n",
       "57                    0.087977  \n",
       "67                    0.105698  \n",
       "124                   0.135501  \n",
       "166                   0.148515  \n",
       "110                   0.181818  \n",
       "71                    0.204082  \n",
       "45                    0.304183  \n",
       "37                    0.323625  \n",
       "50                    0.347826  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bottom 10 countries by coverage: The 10 countries with the lowest total articles per capita (in ascending order) .\n",
    "bottom_10_countries_by_coverage = wp_politicians_by_country_df.groupby([\"country\", \"region\", \"population\"]).size().reset_index(name='total_articles')\n",
    "bottom_10_countries_by_coverage[\"total_articles_per_capita\"] = bottom_10_countries_by_coverage[\"total_articles\"] / bottom_10_countries_by_coverage[\"population\"]\n",
    "\n",
    "bottom_10_countries_by_coverage.sort_values(by=\"total_articles_per_capita\", ascending=True, inplace=True)\n",
    "print(\"Bottom 10 countries by coverage (ascending):\")\n",
    "bottom_10_countries_by_coverage.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality_prediction</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3056711.0</td>\n",
       "      <td>Masoud Khalili</td>\n",
       "      <td>1.246567e+09</td>\n",
       "      <td>GA</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>627316.0</td>\n",
       "      <td>Abdul Salam Zaeef</td>\n",
       "      <td>1.243759e+09</td>\n",
       "      <td>GA</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2202177.0</td>\n",
       "      <td>Fazal Hadi Shinwari</td>\n",
       "      <td>1.242412e+09</td>\n",
       "      <td>GA</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>7249978.0</td>\n",
       "      <td>Ali Pasha of Gusinje</td>\n",
       "      <td>1.244422e+09</td>\n",
       "      <td>GA</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2.7</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>41985495.0</td>\n",
       "      <td>Aqif Pasha Elbasani</td>\n",
       "      <td>1.243883e+09</td>\n",
       "      <td>GA</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2.7</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_id                 title   revision_id article_quality_prediction  \\\n",
       "20   3056711.0        Masoud Khalili  1.246567e+09                         GA   \n",
       "43    627316.0     Abdul Salam Zaeef  1.243759e+09                         GA   \n",
       "54   2202177.0   Fazal Hadi Shinwari  1.242412e+09                         GA   \n",
       "90   7249978.0  Ali Pasha of Gusinje  1.244422e+09                         GA   \n",
       "91  41985495.0   Aqif Pasha Elbasani  1.243883e+09                         GA   \n",
       "\n",
       "        country  population           region  \n",
       "20  Afghanistan        42.4       SOUTH ASIA  \n",
       "43  Afghanistan        42.4       SOUTH ASIA  \n",
       "54  Afghanistan        42.4       SOUTH ASIA  \n",
       "90      Albania         2.7  SOUTHERN EUROPE  \n",
       "91      Albania         2.7  SOUTHERN EUROPE  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the high quality article counts to be used in Analysis 4 and 5\n",
    "high_quality_articles = wp_politicians_by_country_df[wp_politicians_by_country_df[\"article_quality_prediction\"].isin([\"FA\", \"GA\"])]\n",
    "high_quality_articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis 3:\n",
    "\n",
    "Top 10 countries by high quality: The 10 countries with the highest high quality articles per capita (in descending order) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 countries by high quality (descending):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "      <th>total_high_quality</th>\n",
       "      <th>total_high_quality_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Montenegro</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>2.7</td>\n",
       "      <td>7</td>\n",
       "      <td>2.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Kosovo</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Maldives</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>NORTHERN EUROPE</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4</td>\n",
       "      <td>1.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Guyana</td>\n",
       "      <td>SOUTH AMERICA</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Palestinian Territory</td>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Slovenia</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  country           region  population  total_high_quality  \\\n",
       "64             Montenegro  SOUTHERN EUROPE         0.6                   3   \n",
       "57             Luxembourg   WESTERN EUROPE         0.7                   2   \n",
       "1                 Albania  SOUTHERN EUROPE         2.7                   7   \n",
       "51                 Kosovo  SOUTHERN EUROPE         1.7                   4   \n",
       "59               Maldives       SOUTH ASIA         0.6                   1   \n",
       "56              Lithuania  NORTHERN EUROPE         2.9                   4   \n",
       "25                Croatia  SOUTHERN EUROPE         3.8                   5   \n",
       "40                 Guyana    SOUTH AMERICA         0.8                   1   \n",
       "71  Palestinian Territory     WESTERN ASIA         5.5                   6   \n",
       "82               Slovenia  SOUTHERN EUROPE         2.1                   2   \n",
       "\n",
       "    total_high_quality_per_capita  \n",
       "64                       5.000000  \n",
       "57                       2.857143  \n",
       "1                        2.592593  \n",
       "51                       2.352941  \n",
       "59                       1.666667  \n",
       "56                       1.379310  \n",
       "25                       1.315789  \n",
       "40                       1.250000  \n",
       "71                       1.090909  \n",
       "82                       0.952381  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 countries by high quality: The 10 countries with the highest high quality articles per capita (in descending order) .\n",
    "top_10_countries_by_high_quality = high_quality_articles.groupby([\"country\", \"region\", \"population\"]).size().reset_index(name='total_high_quality')\n",
    "top_10_countries_by_high_quality[\"total_high_quality_per_capita\"] = top_10_countries_by_high_quality[\"total_high_quality\"] / top_10_countries_by_high_quality[\"population\"]\n",
    "\n",
    "top_10_countries_by_high_quality.sort_values(by=\"total_high_quality_per_capita\", ascending=False, inplace=True)\n",
    "print(\"Top 10 countries by high quality (descending):\")\n",
    "top_10_countries_by_high_quality.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis 4:\n",
    "\n",
    "Bottom 10 countries by high quality: The 10 countries with the lowest high quality articles per capita (in ascending order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 10 countries by high quality (ascending):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "      <th>total_high_quality</th>\n",
       "      <th>total_high_quality_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>173.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>105.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>126.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Japan</td>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>124.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>240.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>SOUTH AMERICA</td>\n",
       "      <td>52.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Congo DR</td>\n",
       "      <td>MIDDLE AFRICA</td>\n",
       "      <td>102.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>SOUTHEAST ASIA</td>\n",
       "      <td>98.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Uganda</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>48.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>46.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country           region  population  total_high_quality  \\\n",
       "9    Bangladesh       SOUTH ASIA       173.5                   1   \n",
       "29        Egypt  NORTHERN AFRICA       105.2                   1   \n",
       "31     Ethiopia   EASTERN AFRICA       126.5                   2   \n",
       "46        Japan        EAST ASIA       124.5                   2   \n",
       "70     Pakistan       SOUTH ASIA       240.5                   4   \n",
       "22     Colombia    SOUTH AMERICA        52.2                   1   \n",
       "23     Congo DR    MIDDLE AFRICA       102.3                   2   \n",
       "101     Vietnam   SOUTHEAST ASIA        98.9                   2   \n",
       "96       Uganda   EASTERN AFRICA        48.6                   1   \n",
       "2       Algeria  NORTHERN AFRICA        46.8                   1   \n",
       "\n",
       "     total_high_quality_per_capita  \n",
       "9                         0.005764  \n",
       "29                        0.009506  \n",
       "31                        0.015810  \n",
       "46                        0.016064  \n",
       "70                        0.016632  \n",
       "22                        0.019157  \n",
       "23                        0.019550  \n",
       "101                       0.020222  \n",
       "96                        0.020576  \n",
       "2                         0.021368  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bottom 10 countries by high quality: The 10 countries with the lowest high quality articles per capita (in ascending order).\n",
    "bottom_10_countries_by_high_quality = high_quality_articles.groupby([\"country\", \"region\", \"population\"]).size().reset_index(name='total_high_quality')\n",
    "bottom_10_countries_by_high_quality[\"total_high_quality_per_capita\"] = bottom_10_countries_by_high_quality[\"total_high_quality\"] / bottom_10_countries_by_high_quality[\"population\"]\n",
    "\n",
    "bottom_10_countries_by_high_quality.sort_values(by=\"total_high_quality_per_capita\", ascending=True, inplace=True)\n",
    "print(\"Bottom 10 countries by high quality (ascending):\")\n",
    "bottom_10_countries_by_high_quality.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis 5:\n",
    "\n",
    "Geographic regions by total coverage: A rank ordered list of geographic regions (in descending order) by total articles per capita.\n",
    "\n",
    "\n",
    "For this analysis, we need to get the total counts of articles along with population for each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>Population</th>\n",
       "      <th>total_articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>218</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CENTRAL AMERICA</td>\n",
       "      <td>188</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.032967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CENTRAL ASIA</td>\n",
       "      <td>106</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>230</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>0.139563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>664</td>\n",
       "      <td>483.0</td>\n",
       "      <td>1.374741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            region  total_articles  Population  total_articles_per_capita\n",
       "0        CARIBBEAN             218        44.0                   4.954545\n",
       "1  CENTRAL AMERICA             188       182.0                   1.032967\n",
       "2     CENTRAL ASIA             106        80.0                   1.325000\n",
       "3        EAST ASIA             230      1648.0                   0.139563\n",
       "4   EASTERN AFRICA             664       483.0                   1.374741"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_count_per_region = wp_politicians_by_country_df.groupby(['region']).size().reset_index(name='total_articles')\n",
    "articles_count_per_region = pd.merge(articles_count_per_region, population_by_country_df, left_on=[\"region\"], right_on=[\"Geography\"], how=\"left\")\n",
    "articles_count_per_region.drop(columns=[\"Geography\"], inplace=True)\n",
    "\n",
    "# Calculate the total articles per capita for each region\n",
    "articles_count_per_region[\"total_articles_per_capita\"] = articles_count_per_region[\"total_articles\"] / articles_count_per_region[\"Population\"]\n",
    "articles_count_per_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographic regions by total coverage (descending):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>Population</th>\n",
       "      <th>total_articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>796</td>\n",
       "      <td>152.0</td>\n",
       "      <td>5.236842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>218</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>497</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2.497487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>709</td>\n",
       "      <td>285.0</td>\n",
       "      <td>2.487719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>609</td>\n",
       "      <td>299.0</td>\n",
       "      <td>2.036789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NORTHERN EUROPE</td>\n",
       "      <td>191</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.768519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SOUTHERN AFRICA</td>\n",
       "      <td>123</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>72</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>664</td>\n",
       "      <td>483.0</td>\n",
       "      <td>1.374741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SOUTH AMERICA</td>\n",
       "      <td>569</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1.335681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CENTRAL ASIA</td>\n",
       "      <td>106</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>302</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.179688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>521</td>\n",
       "      <td>442.0</td>\n",
       "      <td>1.178733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MIDDLE AFRICA</td>\n",
       "      <td>230</td>\n",
       "      <td>202.0</td>\n",
       "      <td>1.138614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CENTRAL AMERICA</td>\n",
       "      <td>188</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.032967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SOUTHEAST ASIA</td>\n",
       "      <td>395</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0.579179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>670</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>0.330212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>230</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>0.139563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             region  total_articles  Population  total_articles_per_capita\n",
       "0   SOUTHERN EUROPE             796       152.0                   5.236842\n",
       "1         CARIBBEAN             218        44.0                   4.954545\n",
       "2    WESTERN EUROPE             497       199.0                   2.497487\n",
       "3    EASTERN EUROPE             709       285.0                   2.487719\n",
       "4      WESTERN ASIA             609       299.0                   2.036789\n",
       "5   NORTHERN EUROPE             191       108.0                   1.768519\n",
       "6   SOUTHERN AFRICA             123        70.0                   1.757143\n",
       "7           OCEANIA              72        45.0                   1.600000\n",
       "8    EASTERN AFRICA             664       483.0                   1.374741\n",
       "9     SOUTH AMERICA             569       426.0                   1.335681\n",
       "10     CENTRAL ASIA             106        80.0                   1.325000\n",
       "11  NORTHERN AFRICA             302       256.0                   1.179688\n",
       "12   WESTERN AFRICA             521       442.0                   1.178733\n",
       "13    MIDDLE AFRICA             230       202.0                   1.138614\n",
       "14  CENTRAL AMERICA             188       182.0                   1.032967\n",
       "15   SOUTHEAST ASIA             395       682.0                   0.579179\n",
       "16       SOUTH ASIA             670      2029.0                   0.330212\n",
       "17        EAST ASIA             230      1648.0                   0.139563"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Geographic regions by total coverage: A rank ordered list of geographic regions (in descending order) by total articles per capita.\n",
    "regions_by_total_coverage_df = articles_count_per_region.sort_values(by=\"total_articles_per_capita\", ascending=False).reset_index(drop=True)\n",
    "print(\"Geographic regions by total coverage (descending):\")\n",
    "regions_by_total_coverage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis 6:\n",
    "\n",
    "Geographic regions by high quality coverage: Rank ordered list of geographic regions (in descending order) by high quality articles per capita.\n",
    "\n",
    "For this analysis, we need to get the total counts of high quality articles along with population for each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>total_high_quality</th>\n",
       "      <th>Population</th>\n",
       "      <th>total_high_quality_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>9</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.204545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CENTRAL AMERICA</td>\n",
       "      <td>10</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.054945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CENTRAL ASIA</td>\n",
       "      <td>5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>13</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>0.007888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>17</td>\n",
       "      <td>483.0</td>\n",
       "      <td>0.035197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            region  total_high_quality  Population  \\\n",
       "0        CARIBBEAN                   9        44.0   \n",
       "1  CENTRAL AMERICA                  10       182.0   \n",
       "2     CENTRAL ASIA                   5        80.0   \n",
       "3        EAST ASIA                  13      1648.0   \n",
       "4   EASTERN AFRICA                  17       483.0   \n",
       "\n",
       "   total_high_quality_per_capita  \n",
       "0                       0.204545  \n",
       "1                       0.054945  \n",
       "2                       0.062500  \n",
       "3                       0.007888  \n",
       "4                       0.035197  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_quality_articles_count_per_region = high_quality_articles.groupby(['region']).size().reset_index(name='total_high_quality')\n",
    "high_quality_articles_count_per_region = pd.merge(high_quality_articles_count_per_region, population_by_country_df, left_on=[\"region\"], right_on=[\"Geography\"], how=\"left\")\n",
    "high_quality_articles_count_per_region.drop(columns=[\"Geography\"], inplace=True)\n",
    "\n",
    "# Calculate the total articles per capita for each region\n",
    "high_quality_articles_count_per_region[\"total_high_quality_per_capita\"] = high_quality_articles_count_per_region[\"total_high_quality\"] / high_quality_articles_count_per_region[\"Population\"]\n",
    "high_quality_articles_count_per_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographic regions by high quality coverage (descending):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>total_high_quality</th>\n",
       "      <th>Population</th>\n",
       "      <th>total_high_quality_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>53</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.348684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>9</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.204545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>38</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOUTHERN AFRICA</td>\n",
       "      <td>8</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.114286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>21</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.105528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>27</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.090301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NORTHERN EUROPE</td>\n",
       "      <td>9</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>17</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.066406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CENTRAL ASIA</td>\n",
       "      <td>5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CENTRAL AMERICA</td>\n",
       "      <td>10</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.054945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SOUTH AMERICA</td>\n",
       "      <td>19</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0.044601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MIDDLE AFRICA</td>\n",
       "      <td>8</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.039604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOUTHEAST ASIA</td>\n",
       "      <td>25</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0.036657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>17</td>\n",
       "      <td>483.0</td>\n",
       "      <td>0.035197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>13</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>21</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>0.010350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>13</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>0.007888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             region  total_high_quality  Population  \\\n",
       "0   SOUTHERN EUROPE                  53       152.0   \n",
       "1         CARIBBEAN                   9        44.0   \n",
       "2    EASTERN EUROPE                  38       285.0   \n",
       "3   SOUTHERN AFRICA                   8        70.0   \n",
       "4    WESTERN EUROPE                  21       199.0   \n",
       "5      WESTERN ASIA                  27       299.0   \n",
       "6   NORTHERN EUROPE                   9       108.0   \n",
       "7   NORTHERN AFRICA                  17       256.0   \n",
       "8      CENTRAL ASIA                   5        80.0   \n",
       "9   CENTRAL AMERICA                  10       182.0   \n",
       "10    SOUTH AMERICA                  19       426.0   \n",
       "11    MIDDLE AFRICA                   8       202.0   \n",
       "12   SOUTHEAST ASIA                  25       682.0   \n",
       "13   EASTERN AFRICA                  17       483.0   \n",
       "14   WESTERN AFRICA                  13       442.0   \n",
       "15          OCEANIA                   1        45.0   \n",
       "16       SOUTH ASIA                  21      2029.0   \n",
       "17        EAST ASIA                  13      1648.0   \n",
       "\n",
       "    total_high_quality_per_capita  \n",
       "0                        0.348684  \n",
       "1                        0.204545  \n",
       "2                        0.133333  \n",
       "3                        0.114286  \n",
       "4                        0.105528  \n",
       "5                        0.090301  \n",
       "6                        0.083333  \n",
       "7                        0.066406  \n",
       "8                        0.062500  \n",
       "9                        0.054945  \n",
       "10                       0.044601  \n",
       "11                       0.039604  \n",
       "12                       0.036657  \n",
       "13                       0.035197  \n",
       "14                       0.029412  \n",
       "15                       0.022222  \n",
       "16                       0.010350  \n",
       "17                       0.007888  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Geographic regions by high quality coverage: Rank ordered list of geographic regions (in descending order) by high quality articles per capita.\n",
    "regions_by_high_quality_coverage_df = high_quality_articles_count_per_region.sort_values(by=\"total_high_quality_per_capita\", ascending=False).reset_index(drop=True)\n",
    "print(\"Geographic regions by high quality coverage (descending):\")\n",
    "regions_by_high_quality_coverage_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data512",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
